{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npmnzCOpC0lz"
      },
      "source": [
        "## Select / download video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0yhcqVwysnE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e7c26c9-7b3a-403f-9b46-44d571b86fe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yt-dlp in /usr/local/lib/python3.10/dist-packages (2024.11.18)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: openai-whisper==20230124 in /usr/local/lib/python3.10/dist-packages (20230124)\n",
            "Requirement already satisfied: whisper-timestamped in /usr/local/lib/python3.10/dist-packages (1.15.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230124) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230124) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230124) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230124) (10.5.0)\n",
            "Requirement already satisfied: transformers>=4.19.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230124) (4.46.2)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230124) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (1.0.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.36.0)\n",
            "Requirement already satisfied: imageio_ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.5.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from whisper-timestamped) (3.0.11)\n",
            "Requirement already satisfied: dtw-python in /usr/local/lib/python3.10/dist-packages (from whisper-timestamped) (1.5.3)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg>=0.2.0->moviepy) (75.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.26.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (0.20.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dtw-python->whisper-timestamped) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230124) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230124) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230124) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230124) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230124) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20230124) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230124) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install yt-dlp moviepy openai-whisper==20230124 whisper-timestamped"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBL0V-TRUfJM",
        "outputId": "5fe08fb0-27b9-402e-ce42-4db0001b078a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYxy-E-lysnG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import whisper_timestamped\n",
        "from moviepy.editor import VideoFileClip\n",
        "import yt_dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSjZEoN7ysnG"
      },
      "outputs": [],
      "source": [
        "def download_audio_from_youtube(url):\n",
        "    try:\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio/best',\n",
        "            'outtmpl': '%(id)s.%(ext)s',\n",
        "            'postprocessors': [{\n",
        "                'key': 'FFmpegExtractAudio',\n",
        "                'preferredcodec': 'wav',\n",
        "                'preferredquality': '192'\n",
        "            }],\n",
        "            'noplaylist': True,\n",
        "        }\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            info_dict = ydl.extract_info(url, download=True)\n",
        "            audio_file = f\"{info_dict['id']}.wav\"\n",
        "            return audio_file\n",
        "\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTDDQyduysnH"
      },
      "outputs": [],
      "source": [
        "def extract_audio_from_video(video_file):\n",
        "    try:\n",
        "        audio_file = \"extracted_audio.wav\"\n",
        "        video_clip = VideoFileClip(video_file)\n",
        "        video_clip.audio.write_audiofile(audio_file, codec='pcm_s16le', ffmpeg_params=[\"-ac\", \"1\", \"-ar\", \"16000\"])\n",
        "        return audio_file\n",
        "\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "id": "og88BRdhUpNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCMu79OpysnH"
      },
      "outputs": [],
      "source": [
        "def process_audio(audio_file):\n",
        "    try:\n",
        "        print(\"Processing audio file:\", os.path.abspath(audio_file))\n",
        "        if not os.path.exists(audio_file):\n",
        "            return \"Audio file does not exist.\"\n",
        "        audio = AudioSegment.from_file(audio_file)\n",
        "        duration_ms = 3 * 60 * 1000\n",
        "        audio = audio[:duration_ms]\n",
        "\n",
        "        temp_file = \"temp_audio.wav\"\n",
        "        audio.export(temp_file, format=\"wav\")\n",
        "\n",
        "        audio = whisper_timestamped.load_audio(temp_file)\n",
        "        audio = audio / np.max(np.abs(audio))\n",
        "        model = whisper_timestamped.load_model(\"base\", device=\"cpu\")\n",
        "        result = whisper_timestamped.transcribe(model, audio, vad = True, language=\"en\")\n",
        "\n",
        "        # Save results to SRT file\n",
        "        writer = whisper_timestamped.utils.get_writer(\"srt\", \".\")\n",
        "        writer(result, \"output\")\n",
        "        print(f\"SRT file saved: output.srt\")\n",
        "\n",
        "        # Save results to JSON file\n",
        "        json_output_file = \"output.json\"\n",
        "        with open(json_output_file, 'w', encoding='utf-8') as json_file:\n",
        "            json.dump(result, json_file, indent=2, ensure_ascii=False)\n",
        "        print(f\"JSON file saved: {json_output_file}\")\n",
        "\n",
        "        return \"Transcription completed\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return str(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh7t4PoN0_3w"
      },
      "source": [
        "Use Youtube link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTD8RNK6ysnH",
        "outputId": "e40df21b-cc8d-4773-bc36-86b74e958725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube:tab] Extracting URL: https://www.youtube.com/watch?v=XdqPpRRewrE&list=PLBmriQSLAuRJvLNLhRBNso054qvpsqv3t&index=12\n",
            "[youtube:tab] Downloading just the video XdqPpRRewrE because of --no-playlist\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=XdqPpRRewrE\n",
            "[youtube] XdqPpRRewrE: Downloading webpage\n",
            "[youtube] XdqPpRRewrE: Downloading ios player API JSON\n",
            "[youtube] XdqPpRRewrE: Downloading mweb player API JSON\n",
            "[youtube] XdqPpRRewrE: Downloading m3u8 information\n",
            "[info] XdqPpRRewrE: Downloading 1 format(s): 251\n",
            "[download] Destination: XdqPpRRewrE.webm\n",
            "[download] 100% of   15.98MiB in 00:00:00 at 46.56MiB/s  \n",
            "[ExtractAudio] Destination: XdqPpRRewrE.wav\n",
            "Deleting original file XdqPpRRewrE.webm (pass -k to keep)\n",
            "Processing audio file: /content/XdqPpRRewrE.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:76: UserWarning: Performing inference on CPU when CUDA is available\n",
            "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
            "\n",
            "100%|██████████| 17723/17723 [00:53<00:00, 328.40frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRT file saved: output.srt\n",
            "JSON file saved: output.json\n",
            "Transcription completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "youtube_url = 'https://www.youtube.com/watch?v=XdqPpRRewrE&list=PLBmriQSLAuRJvLNLhRBNso054qvpsqv3t&index=12'  # Change this to YouTube URL\n",
        "audio_file = download_audio_from_youtube(youtube_url)\n",
        "if audio_file:\n",
        "    result = process_audio(audio_file)\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t5Gm-Gs1CxA"
      },
      "source": [
        "Use local path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo6FyujxysnI",
        "outputId": "11203614-423a-4642-d817-eb2d42f37cae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing audio file: /content/MoviePy error: the file path_to_your_video_file.mp4 could not be found!\n",
            "Please check that you entered the correct path.\n",
            "Audio file does not exist.\n"
          ]
        }
      ],
      "source": [
        "video_file = 'path_to_your_video_file.mp4'  # Change this to video file path\n",
        "audio_file = extract_audio_from_video(video_file)\n",
        "if audio_file:\n",
        "    result = process_audio(audio_file)\n",
        "    print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_SKONIbC9bo"
      },
      "source": [
        "## Extract timestamp for each word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lgk8iUdQDOIt"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB0NUIZWDBXf",
        "outputId": "e4c0bdf8-9630-4e60-b403-4409545c0f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Okay, let's talk about why we make bad decisions. So if you're like me, then you've probably been in that situation where it's the end of the day or it's the morning and you're thinking like, okay, I'm gonna make a solid plan for myself. Today, I'm gonna be disciplined. I'm gonna come home from work and I'm gonna get all these errands done and I'm gonna treat myself really well. I'm gonna make a nice healthy, proper meal. I'm gonna go to the gym afterwards. I'm gonna exercise and then maybe when I come home, I'll like start reading a book or something. I'll do something a little different, something that makes me feel like I'm gonna advance my life in a new positive direction. And this is our real life volition and it's there to lead you on your way to making good life decisions. But this doesn't always work out that way. Sometimes you get to the end of the day and you realize that you haven't been very disciplined at all. A lot of those errands are still incomplete or like half-started. We didn't end up going to the gym and instead of making a proper meal, we've ordered some definitely not healthy takeout food. And instead of reading that book, maybe you end up watching a show you've already seen and we've not advanced our life in a positive meaningful direction in any way at all. What is happening here? Why would we ignore the voice of volition that's telling us to do all of these beneficial positive things? Well, it could be a lot of things honestly and definitely having like a mental health diagnosis is going to amplify this problem a lot more. But even for the average person, this happens like pretty often. I mean, it certainly happens to me. So what I wanted to share with you today is a framework for understanding why this problem happens and what we can actually do about it. This is a real problem that actually comes up in my work as a therapist kind of often. And I have really enjoyed seeing it demonstrated so clearly and given such a unique role within the structure of a game like Disco Elysium has. So okay, there is a reason that we do not always follow the voice of volition and go through with our good intentions. And it has to do with something called psychological friction. So in this context, friction is any force either internal or external, which opposes a behavioral change. So what do we know about like regular friction, right? If I am standing on an ice rink and I move my body weight around a little bit, I'm gonna start sliding around on the ice. There's not a lot of friction between me and the surface that's under me. When I step off the ice and now I'm standing on concrete, when I shift myself around, I...\n"
          ]
        }
      ],
      "source": [
        "file_path = 'output.json'\n",
        "\n",
        "with open(file_path, 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "print(data[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDerhqtmpQZ7"
      },
      "outputs": [],
      "source": [
        "# This function is to lowracse whole text, easier to re-match and contain big letter \"I\"\n",
        "def lowercase(text):\n",
        "    exceptions = {\"I\", \"I'm\", \"I'll\", \"I've\", \"I'd\"}\n",
        "    words = re.findall(r\"\\b\\w+'\\w+|\\b\\w+\\b|[^\\w\\s]\", text)\n",
        "    processed_words = [\n",
        "        word if word in exceptions else word.lower()\n",
        "        for word in words\n",
        "    ]\n",
        "    result = \" \".join(processed_words)\n",
        "    result = re.sub(r'([?.!,:;])\\s*', r'\\1 ', result)\n",
        "    result = re.sub(r'\\s([?.!,:;])', r'\\1', result)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UtWh7MNpTja",
        "outputId": "4c82573d-2d95-4c77-b40b-bd11cc68db15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "okay, let's talk about why we make bad decisions. so if you're like me, then you've probably been in that situation where it's the end of the day or it's the morning and you're thinking like, okay, I'm gonna make a solid plan for myself. today, I'm gonna be disciplined. I'm gonna come home from work and I'm gonna get all these errands done and I'm gonna treat myself really well. I'm gonna make a nice healthy, proper meal. I'm gonna go to the gym afterwards. I'm gonna exercise and then maybe when I come home, I'll like start reading a book or something. I'll do something a little different, something that makes me feel like I'm gonna advance my life in a new positive direction. and this is our real life volition and it's there to lead you on your way to making good life decisions. but this doesn't always work out that way. sometimes you get to the end of the day and you realize that you haven't been very disciplined at all. a lot of those errands are still incomplete or like half - started. we didn't end up going to the gym and instead of making a proper meal, we've ordered some definitely not healthy takeout food. and instead of reading that book, maybe you end up watching a show you've already seen and we've not advanced our life in a positive meaningful direction in any way at all. what is happening here? why would we ignore the voice of volition that's telling us to do all of these beneficial positive things? well, it could be a lot of things honestly and definitely having like a mental health diagnosis is going to amplify this problem a lot more. but even for the average person, this happens like pretty often. I mean, it certainly happens to me. so what I wanted to share with you today is a framework for understanding why this problem happens and what we can actually do about it. this is a real problem that actually comes up in my work as a therapist kind of often. and I have really enjoyed seeing it demonstrated so clearly and given such a unique role within the structure of a game like disco elysium has. so okay, there is a reason that we do not always follow the voice of volition and go through with our good intentions. and it has to do with something called psychological friction. so in this context, friction is any force either internal or external, which opposes a behavioral change. so what do we know about like regular friction, right? if I am standing on an ice rink and I move my body weight around a little bit, I'm gonna start sliding around on the ice. there's not a lot of friction between me and the surface that's under me. when I step off the ice and now I'm standing on concrete, when I shift myself around, I... \n"
          ]
        }
      ],
      "source": [
        "data[\"text\"] = lowercase(data[\"text\"])\n",
        "print(data[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_word(word):\n",
        "  word = re.sub(r'[,.!?]', '', word)\n",
        "  return word"
      ],
      "metadata": {
        "id": "Vvv3vjI2aR7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNbNTm_RDQNy",
        "outputId": "4a733709-5991-4ef3-cee4-dfd96fe50b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total words extracted: 496\n",
            "Last 5 entries:\n",
            "{'text': 'I', 'start': 178.39, 'end': 178.55}\n",
            "{'text': 'shift', 'start': 178.55, 'end': 178.85}\n",
            "{'text': 'myself', 'start': 178.85, 'end': 179.27}\n",
            "{'text': 'around', 'start': 179.27, 'end': 179.73}\n",
            "{'text': 'I', 'start': 179.97, 'end': 179.99}\n",
            "Extracted data saved to 'extracted_word_timings.json'\n"
          ]
        }
      ],
      "source": [
        "# Extract the desired features\n",
        "word_timings = []\n",
        "for segment in data['segments']:\n",
        "    for word in segment['words']:\n",
        "        word_timing = {\n",
        "            'text': clean_word(word['text']),\n",
        "            'start': word['start'],\n",
        "            'end': word['end']\n",
        "        }\n",
        "        word_timings.append(word_timing)\n",
        "\n",
        "# Print the total number of words extracted\n",
        "print(f\"Total words extracted: {len(word_timings)}\")\n",
        "\n",
        "# Print the last few entries to verify\n",
        "print(\"Last 5 entries:\")\n",
        "for entry in word_timings[-5:]:\n",
        "    print(entry)\n",
        "\n",
        "# Optionally, save to a new JSON file\n",
        "with open('extracted_word_timings.json', 'w') as outfile:\n",
        "    json.dump(word_timings, outfile, indent=2)\n",
        "\n",
        "print(\"Extracted data saved to 'extracted_word_timings.json'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEHKmslXrRXu"
      },
      "source": [
        "## LLM segamentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq_J1IZWrVJn"
      },
      "outputs": [],
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key='AIzaSyB2ApAg4Dk5ctVmhR0XHCKRv6dMGIrCtts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBt6pX02rXU5"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h54n1gz3rbyC"
      },
      "outputs": [],
      "source": [
        "text = data[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtdPJpVArTS6"
      },
      "outputs": [],
      "source": [
        "# Segmentation function\n",
        "def segment_text_gemini(model, text):\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant. Your task is to segment sentences which is longer than 65 characters, including spaces and punctuation, into shorter sentences.\n",
        "Each segmented sentence MUST NOT exceed 65 characters.\n",
        "Each segmented sentence must be independent, complete, and clear, suitable for direct translation or subtitle creation.\n",
        "NOTE: All connecting words (e.g., where, which, and, but, that) MUST remain intact. They should NOT be omitted, split, or modified in any way.\n",
        "\n",
        "Example:\n",
        "Input:\n",
        "so one of the biggest challenges when talking about anything related to mental health whether depression mental illness addiction is it can sometimes be really hard to explain how can you want something\n",
        "Output:\n",
        "so one of the biggest challenges when talking about\n",
        "anything related to mental health\n",
        "whether depression mental illness addiction\n",
        "is it can sometimes be really hard to explain\n",
        "how can you want something:{text}\n",
        "    \"\"\"\n",
        "\n",
        "    # Send request to model\n",
        "    response = model.generate_content(prompt, generation_config=genai.types.GenerationConfig(temperature=0.0))\n",
        "\n",
        "    return response\n",
        "\n",
        "# Get segmented text\n",
        "segmented_output = segment_text_gemini(model, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VbFS--siqcL"
      },
      "outputs": [],
      "source": [
        "# Critic function\n",
        "def critic_text_gemini(model, ori_text, text):\n",
        "    prompt = f\"\"\"\n",
        "    You are a critic.\n",
        "    Your task is to make sure that the content of these sentences is the same as the original,\n",
        "    and if there are differences, revise them according to the original({ori_text}), output should only contain corrected sentences:{text}\n",
        "    \"\"\"\n",
        "\n",
        "    # Send request to model\n",
        "    response = model.generate_content(prompt, generation_config=genai.types.GenerationConfig(temperature=0.0))\n",
        "\n",
        "    return response\n",
        "\n",
        "# Get segmented text\n",
        "segmented = critic_text_gemini(model, text, segmented_output.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "408UQsyS1a4r"
      },
      "source": [
        "## SaT segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-PbfXJ4L1qFK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "c525222c-a136-4603-cf80-7ba1f30c8fb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed adapters-1.0.1 cached-property-2.0.1 coloredlogs-15.0.1 docopt-0.6.2 huggingface-hub-0.25.2 humanfriendly-10.0 mosestokenizer-1.2.1 onnxruntime-1.20.1 openfile-0.0.7 skops-0.10.0 toolwrapper-2.1.0 transformers-4.45.2 uctools-1.3.0 wtpsplit-2.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub",
                  "transformers"
                ]
              },
              "id": "1523568bd9934c47ae00a65a338a3395"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install wtpsplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upw5cFcF2nKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36c7d581-8567-41bf-ae7e-98f28398d0d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Importing from quanto will be deprecated in v4.47. Please install optimum-quanto instrad `pip install optimum-quanto`\n"
          ]
        }
      ],
      "source": [
        "from wtpsplit import SaT\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9b4DUlPBF6A"
      },
      "outputs": [],
      "source": [
        "sat = SaT(\"sat-3l-sm\")\n",
        "sat.half().to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivXYiwlwF1o7"
      },
      "outputs": [],
      "source": [
        "text = data[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvtW8essVW0O"
      },
      "outputs": [],
      "source": [
        "result = sat.split(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "399OopuMHN5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0ab6e8-d98e-443b-cc6b-e7030b2b1392"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"okay, let's talk about why we make bad decisions. \",\n",
              " \"so if you're like me, then you've probably been in that situation where it's the end of the day or it's the morning and you're thinking like, okay, I'm gonna make a solid plan for myself. \",\n",
              " \"today, I'm gonna be disciplined. \",\n",
              " \"I'm gonna come home from work and I'm gonna get all these errands done and I'm gonna treat myself really well. \",\n",
              " \"I'm gonna make a nice healthy, proper meal. \",\n",
              " \"I'm gonna go to the gym afterwards. \",\n",
              " \"I'm gonna exercise and then maybe when I come home, I'll like start reading a book or something. \",\n",
              " \"I'll do something a little different, something that makes me feel like I'm gonna advance my life in a new positive direction. \",\n",
              " \"and this is our real life volition and it's there to lead you on your way to making good life decisions. \",\n",
              " \"but this doesn't always work out that way. \",\n",
              " \"sometimes you get to the end of the day and you realize that you haven't been very disciplined at all. \",\n",
              " 'a lot of those errands are still incomplete or like half - started. ',\n",
              " \"we didn't end up going to the gym and instead of making a proper meal, we've ordered some definitely not healthy takeout food. \",\n",
              " \"and instead of reading that book, maybe you end up watching a show you've already seen and we've not advanced our life in a positive meaningful direction in any way at all. \",\n",
              " 'what is happening here? ',\n",
              " \"why would we ignore the voice of volition that's telling us to do all of these beneficial positive things? \",\n",
              " 'well, it could be a lot of things honestly and definitely having like a mental health diagnosis is going to amplify this problem a lot more. ',\n",
              " 'but even for the average person, this happens like pretty often. ',\n",
              " 'I mean, it certainly happens to me. ',\n",
              " 'so what I wanted to share with you today is a framework for understanding why this problem happens and what we can actually do about it. ',\n",
              " 'this is a real problem that actually comes up in my work as a therapist kind of often. ',\n",
              " 'and I have really enjoyed seeing it demonstrated so clearly and given such a unique role within the structure of a game like disco elysium has. ',\n",
              " 'so okay, there is a reason that we do not always follow the voice of volition and go through with our good intentions. ',\n",
              " 'and it has to do with something called psychological friction. ',\n",
              " 'so in this context, friction is any force either internal or external, which opposes a behavioral change. ',\n",
              " 'so what do we know about like regular friction, right? ',\n",
              " \"if I am standing on an ice rink and I move my body weight around a little bit, I'm gonna start sliding around on the ice. \",\n",
              " \"there's not a lot of friction between me and the surface that's under me. \",\n",
              " \"when I step off the ice and now I'm standing on concrete, when I shift myself around, I... \"]"
            ]
          },
          "metadata": {},
          "execution_count": 262
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9zz0pztRSwx"
      },
      "outputs": [],
      "source": [
        "on_progress = []\n",
        "for i, sentence in enumerate(result):\n",
        "  if len(sentence) > 65:\n",
        "    on_progress.append([i, sentence])\n",
        "    prompt = \"\"\"ou are a helpful assistant. Your task is to segment sentences which is longer than 60 characters(including spaces and punctuation) into several shorter sentences.\n",
        "    Each shorter sentence MUST NOT exceed 60 characters. Each segmented sentence must be independent, complete, and clear, suitable for direct translation or subtitle creation.\n",
        "\n",
        "    NOTE: All connecting words (e.g., where, which, and, but, that) MUST remain intact. They should NOT be omitted, split, or modified in any way.\n",
        "\n",
        "    Example:\n",
        "    Input:\n",
        "    so one of the biggest challenges when talking about anything related to mental health, whether depression mental illness addiction, is it can sometimes be really hard to explain how can you want something.\n",
        "    Output:\n",
        "    so one of the biggest challenges when talking about\n",
        "    anything related to mental health,\n",
        "    whether depression mental illness addiction,\n",
        "    is it can sometimes be really hard to explain\n",
        "    how can you want something.\n",
        "\n",
        "    Make sure you strictly follow the above NOTE and instructions, before you give the answer, check\n",
        "    whether the new sentence is shorter than 60 characters and whether the words in new sentences are the same\n",
        "    as the words in original text, output should only contains shorter sentences. Think step by step:\"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt, generation_config=genai.types.GenerationConfig(temperature=0.0))\n",
        "    print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igRHH28JZJKr"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key='AIzaSyB2ApAg4Dk5ctVmhR0XHCKRv6dMGIrCtts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5DuqIrbZmGL"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAk1dcbuxO63"
      },
      "outputs": [],
      "source": [
        "for i,sentence in on_progress:\n",
        "  prompt ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaHumHMiZo6u"
      },
      "outputs": [],
      "source": [
        "# Segmentation function\n",
        "def segment_text_gemini(model, text, max_length=50):\n",
        "    prompt = f\"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    response = model.generate_content(prompt, generation_config=genai.types.GenerationConfig(temperature=0.0))\n",
        "\n",
        "    return response\n",
        "\n",
        "segmented_output = segment_text_gemini(model, on_progress)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZqJ5tBSt0fI"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Okay let's talk about why we make bad decisions\n",
        "So if you're like me then you've probably been in that situation\n",
        "where it's the end of the day or it's the morning\n",
        "and you're thinking like okay I'm going to make a solid plan for myself\n",
        "Today I'm going to be disciplined\n",
        "I'm going to come home from work and I'm going to get all these errands done\n",
        "and I'm going to treat myself really well\n",
        "I'm going to make a nice healthy proper meal\n",
        "I'm going to go to the gym afterwards\n",
        "I'm going to exercise and th\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNkbd3Dstm0l"
      },
      "source": [
        "## Train SaT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XpFfPswtoUI"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/segment-any-text/wtpsplit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoyEjYlCtxYB"
      },
      "outputs": [],
      "source": [
        "%cd wtpsplit\n",
        "!pip install -r requirements.txt\n",
        "!pip install adapters==0.2.1 --no-dependencies\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Change:\n",
        "\n",
        "/content/wtpsplit/wtpsplit/train/train_lora.py\n",
        "\n",
        "with the NEW train_lora.py\n",
        "\n",
        "Put:\n",
        "\n",
        "lora_dummy_config.json\n",
        "\n",
        "to: /content/wtpsplit/configs/lora\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cNOuoXfrHb5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCDoQ7nIwzyD"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "def extract_srt_text(srt_file_path):\n",
        "    with open(srt_file_path, 'r', encoding='utf-8') as file:\n",
        "        content = file.read()\n",
        "    subtitles = re.findall(r'\\d+\\s+\\d{2}:\\d{2}:\\d{2},\\d{3} --> \\d{2}:\\d{2}:\\d{2},\\d{3}\\s+(.+?)(?=\\n\\n|\\Z)', content, re.DOTALL)\n",
        "    return [subtitle.replace('\\n', ' ').strip() for subtitle in subtitles]\n",
        "\n",
        "def format_srt_to_list(srt_file_paths):\n",
        "    all_subtitles = []\n",
        "    for file_path in srt_file_paths:\n",
        "        subtitles = extract_srt_text(file_path)\n",
        "        all_subtitles.extend([f\"{sentence}\" for sentence in subtitles])\n",
        "    return all_subtitles\n",
        "\n",
        "train_srt_files = glob.glob('/content/Analysis03.srt')\n",
        "test_srt_files = glob.glob('/content/Analysis01.srt')\n",
        "\n",
        "train_text = format_srt_to_list(train_srt_files)\n",
        "test_text = format_srt_to_list(test_srt_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_omILp7hw6_-"
      },
      "outputs": [],
      "source": [
        "print(train_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "kqEo7lHeBtn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXMgtDVPt8i1"
      },
      "outputs": [],
      "source": [
        "torch.save(\n",
        "    {\n",
        "        \"language_code\": {\n",
        "            \"sentence\": {\n",
        "                \"dummy-dataset\": {\n",
        "                    \"meta\": {\n",
        "                        \"train_data\": train_text,\n",
        "                    },\n",
        "                    \"data\": test_text,\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    \"dummy-dataset.pth\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eZLPhVR_Zv1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade huggingface_hub"
      ],
      "metadata": {
        "id": "YcIIts0oCKsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "YTlVj_OCDUH_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers"
      ],
      "metadata": {
        "id": "drJH-YpME2VO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade adapters"
      ],
      "metadata": {
        "id": "VqfyqnoyDoP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "id": "GmJ-Bza3ETR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2B0uAAaxmji"
      },
      "outputs": [],
      "source": [
        "# %cd wtpsplit\n",
        "!python3 wtpsplit/train/train_lora.py configs/lora/lora_dummy_config.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sat_lora_adapted = SaT(\"sat-3l\", lora_path=\"/content/wtpsplit/sat-3l-my/dummy-dataset/language_code/\")"
      ],
      "metadata": {
        "id": "x70TX42VLAfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sat_lora_adapted.split(text)"
      ],
      "metadata": {
        "id": "bBcjDXPyLGJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk1tbjcigpCZ"
      },
      "source": [
        "## Re-match timestamp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nb5cCQhpsGbY"
      },
      "outputs": [],
      "source": [
        "output_sentences = segmented_output.text.split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWIPpjWg2GIU"
      },
      "outputs": [],
      "source": [
        "output_sentences = result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtvA7zxdhKIX"
      },
      "outputs": [],
      "source": [
        "# Clean the text to match the word\n",
        "cleaned_output = []\n",
        "for sentence in output_sentences:\n",
        "  sentence = re.sub(r'[,.!?]', '', sentence)\n",
        "  cleaned_output.append(lowercase(sentence))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5E4tHEPgsov",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a17aaf7-9678-4f7a-ccf5-d2def6664723"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sentence: 'okay let's talk about why we make bad decisions'\n",
            "Total words in sentence: 9, Current total words: 0\n",
            "Processing sentence: 'so if you're like me then you've probably been in that situation where it's the end of the day or it's the morning and you're thinking like okay I'm gonna make a solid plan for myself'\n",
            "Total words in sentence: 36, Current total words: 9\n",
            "Processing sentence: 'today I'm gonna be disciplined'\n",
            "Total words in sentence: 5, Current total words: 45\n",
            "Processing sentence: 'I'm gonna come home from work and I'm gonna get all these errands done and I'm gonna treat myself really well'\n",
            "Total words in sentence: 21, Current total words: 50\n",
            "Processing sentence: 'I'm gonna make a nice healthy proper meal'\n",
            "Total words in sentence: 8, Current total words: 71\n",
            "Processing sentence: 'I'm gonna go to the gym afterwards'\n",
            "Total words in sentence: 7, Current total words: 79\n",
            "Processing sentence: 'I'm gonna exercise and then maybe when I come home I'll like start reading a book or something'\n",
            "Total words in sentence: 18, Current total words: 86\n",
            "Processing sentence: 'I'll do something a little different something that makes me feel like I'm gonna advance my life in a new positive direction'\n",
            "Total words in sentence: 22, Current total words: 104\n",
            "Processing sentence: 'and this is our real life volition and it's there to lead you on your way to making good life decisions'\n",
            "Total words in sentence: 21, Current total words: 126\n",
            "Processing sentence: 'but this doesn't always work out that way'\n",
            "Total words in sentence: 8, Current total words: 147\n",
            "Processing sentence: 'sometimes you get to the end of the day and you realize that you haven't been very disciplined at all'\n",
            "Total words in sentence: 20, Current total words: 155\n",
            "Processing sentence: 'a lot of those errands are still incomplete or like half - started'\n",
            "Total words in sentence: 13, Current total words: 175\n",
            "Processing sentence: 'we didn't end up going to the gym and instead of making a proper meal we've ordered some definitely not healthy takeout food'\n",
            "Total words in sentence: 23, Current total words: 188\n",
            "Processing sentence: 'and instead of reading that book maybe you end up watching a show you've already seen and we've not advanced our life in a positive meaningful direction in any way at all'\n",
            "Total words in sentence: 32, Current total words: 211\n",
            "Processing sentence: 'what is happening here'\n",
            "Total words in sentence: 4, Current total words: 243\n",
            "Processing sentence: 'why would we ignore the voice of volition that's telling us to do all of these beneficial positive things'\n",
            "Total words in sentence: 19, Current total words: 247\n",
            "Processing sentence: 'well it could be a lot of things honestly and definitely having like a mental health diagnosis is going to amplify this problem a lot more'\n",
            "Total words in sentence: 26, Current total words: 266\n",
            "Processing sentence: 'but even for the average person this happens like pretty often'\n",
            "Total words in sentence: 11, Current total words: 292\n",
            "Processing sentence: 'I mean it certainly happens to me'\n",
            "Total words in sentence: 7, Current total words: 303\n",
            "Processing sentence: 'so what I wanted to share with you today is a framework for understanding why this problem happens and what we can actually do about it'\n",
            "Total words in sentence: 26, Current total words: 310\n",
            "Processing sentence: 'this is a real problem that actually comes up in my work as a therapist kind of often'\n",
            "Total words in sentence: 18, Current total words: 336\n",
            "Processing sentence: 'and I have really enjoyed seeing it demonstrated so clearly and given such a unique role within the structure of a game like disco elysium has'\n",
            "Total words in sentence: 26, Current total words: 354\n",
            "Processing sentence: 'so okay there is a reason that we do not always follow the voice of volition and go through with our good intentions'\n",
            "Total words in sentence: 23, Current total words: 380\n",
            "Processing sentence: 'and it has to do with something called psychological friction'\n",
            "Total words in sentence: 10, Current total words: 403\n",
            "Processing sentence: 'so in this context friction is any force either internal or external which opposes a behavioral change'\n",
            "Total words in sentence: 17, Current total words: 413\n",
            "Processing sentence: 'so what do we know about like regular friction right'\n",
            "Total words in sentence: 10, Current total words: 430\n",
            "Processing sentence: 'if I am standing on an ice rink and I move my body weight around a little bit I'm gonna start sliding around on the ice'\n",
            "Total words in sentence: 26, Current total words: 440\n",
            "Processing sentence: 'there's not a lot of friction between me and the surface that's under me'\n",
            "Total words in sentence: 14, Current total words: 466\n",
            "Processing sentence: 'when I step off the ice and now I'm standing on concrete when I shift myself around I'\n",
            "Total words in sentence: 18, Current total words: 480\n",
            "Warning: Index out of range. start_word_id: 481, end_word_id: 498\n",
            "word_timings length: 496\n"
          ]
        }
      ],
      "source": [
        "result = []\n",
        "current_id = 0\n",
        "\n",
        "for sentence in cleaned_output:\n",
        "    words = sentence.split()\n",
        "    num_words = len(words)\n",
        "\n",
        "    if num_words == 0:\n",
        "        continue\n",
        "\n",
        "    start_word_id = current_id + 1\n",
        "    end_word_id = current_id + num_words\n",
        "\n",
        "    print(f\"Processing sentence: '{sentence}'\")\n",
        "    print(f\"Total words in sentence: {num_words}, Current total words: {current_id}\")\n",
        "\n",
        "    if start_word_id > len(word_timings) or end_word_id > len(word_timings):\n",
        "        print(f\"Warning: Index out of range. start_word_id: {start_word_id}, end_word_id: {end_word_id}\")\n",
        "        print(f\"word_timings length: {len(word_timings)}\")\n",
        "        continue\n",
        "    try:\n",
        "        start_time = word_timings[start_word_id - 1]['start']\n",
        "        end_time = word_timings[end_word_id - 1]['end']\n",
        "    except IndexError as e:\n",
        "        print(f\"Error: Index error when accessing word_timings. {e}\")\n",
        "        continue\n",
        "\n",
        "    result.append({\n",
        "        'sentence': sentence,\n",
        "        'start': start_time,\n",
        "        'end': end_time\n",
        "    })\n",
        "\n",
        "    current_id += num_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpAL8poug5-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b6193c-908a-44f5-9c29-3ff7af1cfde2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sentence': \"okay let's talk about why we make bad decisions\", 'start': 3.31, 'end': 6.37}\n",
            "{'sentence': \"so if you're like me then you've probably been in that situation where it's the end of the day or it's the morning and you're thinking like okay I'm gonna make a solid plan for myself\", 'start': 6.87, 'end': 17.67}\n",
            "{'sentence': \"today I'm gonna be disciplined\", 'start': 18.33, 'end': 20.29}\n",
            "{'sentence': \"I'm gonna come home from work and I'm gonna get all these errands done and I'm gonna treat myself really well\", 'start': 21.17, 'end': 27.02}\n",
            "{'sentence': \"I'm gonna make a nice healthy proper meal\", 'start': 27.02, 'end': 30.53}\n"
          ]
        }
      ],
      "source": [
        "for entry in result[:5]:\n",
        "    print(entry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiHI6jeiYJeH"
      },
      "source": [
        "# Transform into .SRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDNZxxfJYN3-"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds):\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
        "    return f\"{hours:02}:{minutes:02}:{secs:02},{milliseconds:03}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37PAm79QYZJK"
      },
      "outputs": [],
      "source": [
        "def generate_srt(data):\n",
        "    srt_lines = []\n",
        "    for index, item in enumerate(data):\n",
        "        start_time = format_time(item['start'])\n",
        "        end_time = format_time(item['end'])\n",
        "        sentence = item['sentence']\n",
        "\n",
        "        srt_lines.append(f\"{index + 1}\")\n",
        "        srt_lines.append(f\"{start_time} --> {end_time}\")\n",
        "        srt_lines.append(sentence)\n",
        "        srt_lines.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(srt_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shEfRUpDYefS"
      },
      "outputs": [],
      "source": [
        "def save_srt(filename, srt_content):\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(srt_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwU9bhyPYgFA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "558b8212-af52-4b58-ef19-9092303a9e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRT file has been saved as 'output.srt'\n"
          ]
        }
      ],
      "source": [
        "srt_content = generate_srt(result)\n",
        "\n",
        "save_srt(\"output.srt\", srt_content)\n",
        "\n",
        "print(\"SRT file has been saved as 'output.srt'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "rEHKmslXrRXu",
        "TNkbd3Dstm0l"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}