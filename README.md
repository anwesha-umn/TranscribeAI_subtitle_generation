# TranscribeAI_subtitle_generation

This research aims to enhance video subtitle alignment
and segmentation for better accessibility and
viewing experiences. Key objectives include:

1. Utilizing fine tuned Whisper models for translating speech to text.

2. Implementing text segmentation techniques
with state-of-the-art language models for generating refined subtitles of reasonable length.

3. Creating a robust methodology to validate caption
quality across content types.

4. Aligning subtitles appropriately to speech without altering
original video timestamps.


# Streamlit GUI

The [app_transcribe.py](https://github.com/anwesha-umn/TranscribeAI_subtitle_generation/blob/main/app_transcribe.py)  file includes code for implemeting the GUI. 

Use the following command to run the app: 
`streamlit run app_transcribe.py`.

Here is a snapshot of the interface:

![Display of GUI, downloading audio and
video from a YouTube link given as input and generating
Improved SRT file for Subtitles]([URL or relative path to image](https://github.com/anwesha-umn/TranscribeAI_subtitle_generation/blob/main/images/gui1.png))
